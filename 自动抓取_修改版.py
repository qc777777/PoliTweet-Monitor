import tweepy
from pymongo import MongoClient
from textblob import TextBlob
import schedule
import time
from datetime import datetime
import sys
import io
import os
from dotenv import load_dotenv
from è¯­ä¹‰åˆ†æ import analyze_tweet
from è­¦æŠ¥ç³»ç»Ÿ import send_alert_if_needed

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# ---------- é…ç½®åŒº ----------
# ä»ç¯å¢ƒå˜é‡è·å–APIå¯†é’¥ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨å ä½ç¬¦
BEARER_TOKEN = os.getenv("TWITTER_BEARER_TOKEN")Â  

# å¦‚æœä½¿ç”¨å ä½ç¬¦ï¼Œæç¤ºç”¨æˆ·é…ç½®
if BEARER_TOKEN == "your_bearer_token_here":
    print("âš ï¸ è¯·åœ¨.envæ–‡ä»¶ä¸­é…ç½®TWITTER_BEARER_TOKEN")
    print("æˆ–è€…ç›´æ¥åœ¨æ­¤å¤„æ›¿æ¢BEARER_TOKENå˜é‡")

MAX_TWEETS_PER_PERSON = 5
SLEEP_BETWEEN_USERS = 10  # ç§’
FETCH_INTERVAL_HOURS = 2  # æ¯å‡ å°æ—¶æŠ“ä¸€æ¬¡

# é¢†å¯¼äººè´¦å·ï¼ˆç”¨æˆ·å â†’ ä¸­æ–‡åç§°ï¼‰
LEADER_ACCOUNTS = {
    "realDonaldTrump": "ç‰¹æœ—æ™®",
    "POTUS": "æ‹œç™»",
    "KremlinRussia_E": "æ™®äº¬",
    "RishiSunak": "è‹çº³å…‹",
    "EmmanuelMacron": "é©¬å…‹é¾™",
    "netanyahu": "å†…å¡”å°¼äºšèƒ¡",
    "ZelenskyyUa": "æ³½è¿æ–¯åŸº"
}

# é»‘å¤©é¹…å…³é”®è¯
BLACK_SWAN_KEYWORDS = [
    "resign", "nuclear", "assassinate", "collapse", "shutdown", "default",
    "emergency", "war", "coup", "strike", "riot", "dead", "çˆ†ç‚¸", "å±æœº"
]

# ---------- åˆå§‹åŒ– ----------
# è¾“å‡ºé˜² emoji æŠ¥é”™
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

# æ£€æŸ¥APIå¯†é’¥
if BEARER_TOKEN == "your_bearer_token_here":
    print("âŒ è¯·å…ˆé…ç½®Twitter APIå¯†é’¥")
    sys.exit(1)

client_twitter = tweepy.Client(
    bearer_token=BEARER_TOKEN,
    wait_on_rate_limit=True
)

client_mongo = MongoClient("mongodb://localhost:27017/")
db = client_mongo["twitter_monitor"]
collection = db["tweets"]

# âš ï¸ ç¼“å­˜ user_idï¼Œé¿å…å¤šæ¬¡è¯·æ±‚ get_user()
USER_ID_CACHE = {}

# ---------- å·¥å…·å‡½æ•° ----------

def analyze_sentiment(text):
    blob = TextBlob(text)
    polarity = blob.sentiment.polarity
    if polarity > 0.2:
        return "æ­£é¢"
    elif polarity < -0.2:
        return "è´Ÿé¢"
    else:
        return "ä¸­æ€§"

def contains_black_swan_keywords(text):
    text_lower = text.lower()
    return any(kw.lower() in text_lower for kw in BLACK_SWAN_KEYWORDS)

def safe_print(msg):
    try:
        print(msg)
    except Exception:
        print(msg.encode("utf-8", errors="ignore").decode("utf-8"))

# ---------- æŠ“å–å•è´¦å· ----------
def fetch_user_tweets(username):
    try:
        # ä»ç¼“å­˜ä¸­è·å– user_idï¼Œé¿å…é‡å¤è¯·æ±‚
        if username in USER_ID_CACHE:
            user_id = USER_ID_CACHE[username]
        else:
            user = client_twitter.get_user(username=username)
            user_id = user.data.id
            USER_ID_CACHE[username] = user_id

        tweets = client_twitter.get_users_tweets(
            id=user_id,
            max_results=MAX_TWEETS_PER_PERSON,
            tweet_fields=["created_at", "text", "lang"]
        )

        if tweets.data is None:
            safe_print(f"âš ï¸ {username} æ— æ–°æ¨æ–‡ã€‚")
            return

        for tweet in tweets.data:
            # ä½¿ç”¨å¢å¼ºçš„è¯­ä¹‰åˆ†æ
            analysis_result = analyze_tweet(tweet.text)
            
            tweet_dict = {
                "id": tweet.id,
                "created_at": tweet.created_at.isoformat(),
                "text": tweet.text,
                "author_id": tweet.author_id,
                "username": username,
                # ä¿æŒå‘åå…¼å®¹
                "sentiment": analysis_result['sentiment_label'],
                "black_swan": analysis_result['is_black_swan'],
                # æ–°å¢å­—æ®µ
                "sentiment_score": analysis_result['sentiment_score'],
                "confidence": analysis_result['confidence'],
                "risk_score": analysis_result['risk_score'],
                "urgency_level": analysis_result['urgency_level'],
                "alert_level": analysis_result['alert_level'],
                "detected_categories": analysis_result['detected_categories'],
                "analyzed_at": analysis_result['analyzed_at']
            }

            collection.update_one(
                {"id": tweet.id},
                {"$set": tweet_dict},
                upsert=True
            )

            # æ£€æŸ¥æ˜¯å¦éœ€è¦å‘é€è­¦æŠ¥
            if analysis_result['is_black_swan']:
                send_alert_if_needed(tweet_dict)

            # æ˜¾ç¤ºçŠ¶æ€
            if analysis_result['is_black_swan']:
                flag = f"ğŸš¨ {analysis_result['alert_level']}"
            else:
                flag = "âœ…"
            
            msg = f"{flag} [{tweet.created_at}] {username}: {tweet.text[:60]}..."
            safe_print(msg)

    except Exception as e:
        safe_print(f"âŒ é”™è¯¯ï¼ˆ{username}ï¼‰: {e}")

# ---------- æ‰¹é‡æŠ“å– ----------
def fetch_all_leaders():
    safe_print(f"\nğŸ• {datetime.utcnow().isoformat()} æ­£åœ¨æŠ“å–æ¨æ–‡...\n")
    for username in LEADER_ACCOUNTS:
        fetch_user_tweets(username)
        safe_print(f"â± å·²æŠ“å– {username}ï¼Œç­‰å¾… {SLEEP_BETWEEN_USERS} ç§’...\n")
        time.sleep(SLEEP_BETWEEN_USERS)

# ---------- å®šæ—¶è°ƒåº¦ ----------
if __name__ == "__main__":
    safe_print(f"ğŸ“¡ èˆ†æƒ…ç›‘æ§å¯åŠ¨ï¼Œæ¯ {FETCH_INTERVAL_HOURS} å°æ—¶æ‰§è¡Œä¸€æ¬¡...")
    fetch_all_leaders()  # å¯åŠ¨å³æ‰§è¡Œä¸€æ¬¡
    schedule.every(FETCH_INTERVAL_HOURS).hours.do(fetch_all_leaders)

    while True:
        schedule.run_pending()
        time.sleep(10)
